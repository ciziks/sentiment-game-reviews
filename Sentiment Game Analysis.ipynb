{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Sentimental do Review de Jogos\n",
    "\n",
    "## Projeto da disciplina **SSC0287 - Mineração de Dados Não Estruturados**\n",
    "\n",
    "- Lucas Ivars Cadima Ciziks - luciziks@usp.br - 12559472\n",
    "\n",
    "- Gustavo Silva de Oliveira - guspfc03@usp.br - 12567231\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo principal desse trabalho é **sumarizar informações textuais** no contexto de **Review de Jogos por Usuários**, utilizando as técnicas de Mineração de Dados Textuais aprendidas no decorrer da disciplina. Dentro de plataformas de games, como a Steam e Epic Games, é comum cada jogo ter uma seção contendo a avaliação geral dos usuários que já jogaram. Desse modo, novos compradores podem ter uma ideia do que esperar de um jogo. \n",
    "\n",
    "\n",
    "Nesse contexto, nossa abordagem visa extrair o sentimento geral na opinião de um usuário ao descrever sua experiência jogando determinado jogo, verificando, assim, se a avaliação foi **Positiva**, **Negativa** ou **Neutra**. Para isso, treinamos um modelo base do [BERT](https://huggingface.co/bert-base-uncased) com uma base de avaliações de jogos advindas do Twitter. Desse modo, o modelo é capaz de analisar a linguagem complexa presente nos reviews e traduzi-lá em informação resumida.\n",
    "\n",
    "Além disso, treinamos um segundo modelo dedicado à detecção de discurso de ódio, classificando o texto como **Discurso de Ódio**, **Linguagem ofensiva** ou **Nada Detectado** nos reviews. Assim, em um caso real como na plataforma Steam, o uso combinado desses modelos permite coletar informações diretas sobre os jogos, além de evitar a disseminação de conteúdos prejudiciais nesses fóruns.\n",
    "\n",
    "Com perspectiva para futuras melhorias, propomos a implementação da explicabilidade dos modelos. Esse aprimoramento permitirá uma compreensão mais clara sobre os motivos específicos que contribuem para o sentimento geral ser positivo, negativo ou neutro. Ademais, identificar quais palavras específicas foram a razão para se qualificar a review como discurso de ódio ou linguagem ofensiva seria útil para eventuais censuras ou aviso ao usuário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O projeto foi desenvolvido na linguagem **Python**, utilizando o [Poetry](https://python-poetry.org) para gerenciamento das dependências. Dentre as bibliotecas utilizadas, estão:\n",
    "\n",
    "* [Pandas](https://pandas.pydata.org);\n",
    "* [Scikit-learn](https://scikit-learn.org/stable/);\n",
    "* [Keras](https://keras.io);\n",
    "* [HuggingFace](https://huggingface.co/docs/huggingface_hub/index).\n",
    "\n",
    "Antes de rodar o notebook, certifique-se de instalar todas as depências através do comando:\n",
    "\n",
    "```poetry install```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As bases de dados utilizadas neste projeto podem ser encontradas em:\n",
    "\n",
    "* [Análise de Sentimentos](https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis);\n",
    "* [Detecção de Discurso de Ódio](https://www.kaggle.com/datasets/mexwell/hate-speech-identification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Dependências do Projeto\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Dropout\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from transformers import (\n",
    "    TFBertModel,\n",
    "    BertTokenizer,\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo a base de dados\n",
    "\n",
    "sentimental_analysis_data = pd.read_csv(\"https://raw.githubusercontent.com/ciziks/sentiment-game-reviews/main/training_data/sentimental_analysis_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomeando as colunas, removendo valores nulos e tomando apenas as variáveis de interesse\n",
    "\n",
    "sentimental_analysis_data.columns = [\"id\", \"palavra-chave\", \"sentimento\", \"tweet\"]\n",
    "\n",
    "sentimental_analysis_data.dropna(inplace=True)\n",
    "\n",
    "sentimental_analysis_data = sentimental_analysis_data[[\"tweet\", \"sentimento\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapeando a variável de interesse para valores numéricos interpretáveis pelo modelo de treinamento (foi tomada a decisão de\n",
    "# agrupar as respostas \"Neutral\" e \"Irrelevant\" na mesma categoria)\n",
    "\n",
    "mapeamento = {\"Positive\": 0, \"Neutral\": 1, \"Negative\": 2, \"Irrelevant\": 1}\n",
    "\n",
    "sentimental_analysis_data[\"sentimento\"] = sentimental_analysis_data[\"sentimento\"].map(mapeamento)\n",
    "\n",
    "sentimental_analysis_data[\"sentimento\"] = sentimental_analysis_data[\"sentimento\"].astype(int)\n",
    "\n",
    "# dividindo em datasets de treino e teste\n",
    "\n",
    "sentimental_analysis_train, sentimental_analysis_test = train_test_split(sentimental_analysis_data, test_size=0.2, random_state = 42)\n",
    "\n",
    "sentimental_analysis_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo os dados para o formato 'Dataset', amplamente utilizado no treinamento de modelos de aprendizdo\n",
    "\n",
    "sentimental_analysis_train = Dataset.from_pandas(sentimental_analysis_train)\n",
    "sentimental_analysis_test = Dataset.from_pandas(sentimental_analysis_test)\n",
    "\n",
    "sentimental_analysis_dataset = DatasetDict({\"train\": sentimental_analysis_train, \"test\": sentimental_analysis_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Identificação de Discurso de Ódio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo a base de dados\n",
    "\n",
    "hate_speech_data = pd.read_csv(\"https://raw.githubusercontent.com/ciziks/sentiment-game-reviews/main/training_data/hate_speech_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tomando apenas as variáveis de interesse e renomeando-as\n",
    "\n",
    "hate_speech_data = hate_speech_data[[\"tweet\", \"class\"]]\n",
    "\n",
    "hate_speech_data.rename(columns={\"class\": \"label\", \"tweet\": \"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividindo em datasets de treino e teste\n",
    "\n",
    "hate_speech_train, hate_speech_test = train_test_split(hate_speech_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo os dados para o formato 'DatasetDict', amplamente utilizado no treinamento de modelos de aprendizdo\n",
    "\n",
    "hate_speech_train = Dataset.from_pandas(hate_speech_train)\n",
    "hate_speech_test = Dataset.from_pandas(hate_speech_test)\n",
    "\n",
    "hate_speech_dataset = DatasetDict({\"train\": hate_speech_train, \"test\": hate_speech_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extração de Padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando o tokenzier do modelo base do BERT\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao utilizada para tokenizar as entradas\n",
    "\n",
    "def tokenize_function_sentimental(example):\n",
    "    return tokenizer(example[\"tweet\"], truncation=True)\n",
    "\n",
    "def tokenize_function_hate_speech(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# carregando o modelo base do BERT\n",
    "\n",
    "model_sentimental = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=3\n",
    ")\n",
    "\n",
    "model_hate_speech = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# especificando o data collator para TensorFlow\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizando o dataset\n",
    "\n",
    "sentimental_analysis_tokenized = sentimental_analysis_dataset.map(tokenize_function_sentimental, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo os dados para o formato TensorFlow\n",
    "# aqui ja se especifica o tamanho do batch em 8\n",
    "\n",
    "sentimental_analysis_train_tf = sentimental_analysis_tokenized[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"sentimento\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "sentimental_analysis_validation_tf = sentimental_analysis_tokenized[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"sentimento\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# especificando parâmetros importantes (learning rate, loss, métrica e número de épocas) e treinando o modelo\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model_sentimental.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "model_sentimental.fit(sentimental_analysis_train_tf, validation_data=sentimental_analysis_validation_tf, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Identificação de Discurso de Ódio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizando o dataset\n",
    "\n",
    "hate_speech_tokenized = hate_speech_dataset.map(tokenize_function_hate_speech, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo os dados para o formato TensorFlow\n",
    "# aqui ja se especifica o tamanho do batch em 8\n",
    "\n",
    "hate_speech_train_tf = hate_speech_tokenized[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "hate_speech_validation_tf = hate_speech_tokenized[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# especificando parâmetros importantes (learning rate, loss, métrica e número de épocas) e treinando o modelo\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model_hate_speech.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "model_hate_speech.fit(hate_speech_train_tf, validation_data=hate_speech_validation_tf, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook, por motivos de otimização de tempo, optou-se por não executar os modelos de treinamento. Todavia, é possível encontrar os Notebooks com todas as etapas executadas no [Github](https://github.com/ciziks/sentiment-game-reviews) do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pós-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o treinamento, os modelos foram carregados na plataforma *HuggingFace*, que nos permite carregar os modelos já treinados e utilizá-los, sem a necessidade de treinar novamente. Você pode encontrar os modelos em:\n",
    "\n",
    "* [Modelo para Análises de Sentimentos](https://huggingface.co/Guspfc/my-awesome-bert-model-sentiment-analysis);\n",
    "* [Modelo para Identificação de Discurso de Ódio](https://huggingface.co/Guspfc/my-awesome-bert-model-sentiment-analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Uso do Conhecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fim utilizar os modelos de **Análise de Sentimento** e **Detecção de Discurso de Ódio** treinados nas etapas anteriores, construímos um site para coletar a opinião do usuário acerca dos nomeados a Game of The Year 2023 e verificar o sentimento geral e se houve discurso de ódio na descrição.\n",
    "\n",
    "Para isso, utilizamos o [Streamlit](https://docs.streamlit.io), uma biblioteca do Python que facilita a implementação de uma interface gráfica para projetos de Machine Learning e Data Science. O código está disponível no arquivo `app.py` e é possível executá-lo localmente através do comando:\n",
    "\n",
    "```poetry run streamlit run app.py```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
